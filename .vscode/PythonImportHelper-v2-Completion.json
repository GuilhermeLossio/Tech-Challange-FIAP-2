[
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "jmespath",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jmespath",
        "description": "jmespath",
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Iterable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "boto3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "boto3",
        "description": "boto3",
        "detail": "boto3",
        "documentation": {}
    },
    {
        "label": "ClientError",
        "importPath": "botocore.exceptions",
        "description": "botocore.exceptions",
        "isExtraImport": true,
        "detail": "botocore.exceptions",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "date",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "B3Scraper",
        "importPath": "WebScrapping",
        "description": "WebScrapping",
        "isExtraImport": true,
        "detail": "WebScrapping",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "dataclass",
        "importPath": "dataclasses",
        "description": "dataclasses",
        "isExtraImport": true,
        "detail": "dataclasses",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "pyarrow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyarrow",
        "description": "pyarrow",
        "detail": "pyarrow",
        "documentation": {}
    },
    {
        "label": "pyarrow.parquet",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyarrow.parquet",
        "description": "pyarrow.parquet",
        "detail": "pyarrow.parquet",
        "documentation": {}
    },
    {
        "label": "yfinance",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yfinance",
        "description": "yfinance",
        "detail": "yfinance",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "B3Scraper",
        "importPath": "ingestion.WebScrapping",
        "description": "ingestion.WebScrapping",
        "isExtraImport": true,
        "detail": "ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": ".venv.Scripts.jp",
        "description": ".venv.Scripts.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": ".venv.Scripts.jp",
        "documentation": {}
    },
    {
        "label": "S3BucketClient",
        "kind": 6,
        "importPath": "AwsFunctions.AwsFunctions",
        "description": "AwsFunctions.AwsFunctions",
        "peekOfCode": "class S3BucketClient:\n    \"\"\"Small wrapper for common S3 operations in a single bucket.\"\"\"\n    def __init__(\n        self,\n        bucket_name: str,\n        region_name: Optional[str] = None,\n        aws_access_key_id: Optional[str] = None,\n        aws_secret_access_key: Optional[str] = None,\n        aws_session_token: Optional[str] = None,\n        client: Optional[Any] = None,",
        "detail": "AwsFunctions.AwsFunctions",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.ingestion.run_ingestion",
        "description": "src.ingestion.run_ingestion",
        "peekOfCode": "def main() -> None:\n    scraper = B3Scraper(\n        tickers=TICKERS,\n        period=\"5d\",     # small window to guarantee D-1 availability\n        interval=\"1d\",\n    )\n    uris = scraper.save_to_s3_partitioned(\n        bucket=S3_BUCKET,\n        prefix=RAW_PREFIX,\n        dt=DT,",
        "detail": "src.ingestion.run_ingestion",
        "documentation": {}
    },
    {
        "label": "DT",
        "kind": 5,
        "importPath": "src.ingestion.run_ingestion",
        "description": "src.ingestion.run_ingestion",
        "peekOfCode": "DT = (date.today() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n# Airline sector tickers (B3)\nTICKERS = \"GOLL4,AZUL4,EMBR3,EVEB31\"\n# Raw data lake location\nS3_BUCKET = \"aeronaticalverifier-s3\"\nRAW_PREFIX = \"raw\"\n# ---------------------------------------------------------\n# Ingestion\n# ---------------------------------------------------------\ndef main() -> None:",
        "detail": "src.ingestion.run_ingestion",
        "documentation": {}
    },
    {
        "label": "TICKERS",
        "kind": 5,
        "importPath": "src.ingestion.run_ingestion",
        "description": "src.ingestion.run_ingestion",
        "peekOfCode": "TICKERS = \"GOLL4,AZUL4,EMBR3,EVEB31\"\n# Raw data lake location\nS3_BUCKET = \"aeronaticalverifier-s3\"\nRAW_PREFIX = \"raw\"\n# ---------------------------------------------------------\n# Ingestion\n# ---------------------------------------------------------\ndef main() -> None:\n    scraper = B3Scraper(\n        tickers=TICKERS,",
        "detail": "src.ingestion.run_ingestion",
        "documentation": {}
    },
    {
        "label": "S3_BUCKET",
        "kind": 5,
        "importPath": "src.ingestion.run_ingestion",
        "description": "src.ingestion.run_ingestion",
        "peekOfCode": "S3_BUCKET = \"aeronaticalverifier-s3\"\nRAW_PREFIX = \"raw\"\n# ---------------------------------------------------------\n# Ingestion\n# ---------------------------------------------------------\ndef main() -> None:\n    scraper = B3Scraper(\n        tickers=TICKERS,\n        period=\"5d\",     # small window to guarantee D-1 availability\n        interval=\"1d\",",
        "detail": "src.ingestion.run_ingestion",
        "documentation": {}
    },
    {
        "label": "RAW_PREFIX",
        "kind": 5,
        "importPath": "src.ingestion.run_ingestion",
        "description": "src.ingestion.run_ingestion",
        "peekOfCode": "RAW_PREFIX = \"raw\"\n# ---------------------------------------------------------\n# Ingestion\n# ---------------------------------------------------------\ndef main() -> None:\n    scraper = B3Scraper(\n        tickers=TICKERS,\n        period=\"5d\",     # small window to guarantee D-1 availability\n        interval=\"1d\",\n    )",
        "detail": "src.ingestion.run_ingestion",
        "documentation": {}
    },
    {
        "label": "B3Scraper",
        "kind": 6,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "class B3Scraper:\n    def __init__(\n        self,\n        tickers: Union[str, Iterable[str]],\n        start: Optional[str] = None,\n        end: Optional[str] = None,\n        period: str = \"1y\",\n        interval: str = \"1d\",\n        output: str = \"b3_data.parquet\",\n    ) -> None:",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "normalize_tickers",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def normalize_tickers(raw: str) -> List[str]:\n    \"\"\"\n    Normalize a comma-separated string of tickers.\n    Ensures B3 tickers end with '.SA' unless they are indices (e.g. ^BVSP).\n    \"\"\"\n    tickers: List[str] = []\n    for part in raw.split(\",\"):\n        ticker = part.strip().upper()\n        if not ticker:\n            continue",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "normalize_tickers_input",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def normalize_tickers_input(raw: Union[str, Iterable[str]]) -> List[str]:\n    \"\"\"\n    Accepts either a string or an iterable of tickers and normalizes them.\n    \"\"\"\n    if isinstance(raw, str):\n        return normalize_tickers(raw)\n    tickers: List[str] = []\n    for part in raw:\n        ticker = str(part).strip().upper()\n        if not ticker:",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "download_data",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def download_data(\n    tickers: List[str],\n    start: Optional[str],\n    end: Optional[str],\n    period: str,\n    interval: str,\n) -> pd.DataFrame:\n    \"\"\"\n    Download historical market data from yfinance.\n    \"\"\"",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "normalize_download",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def normalize_download(data: pd.DataFrame, tickers: List[str]) -> pd.DataFrame:\n    \"\"\"\n    Normalize yfinance output into a flat tabular format.\n    Output schema:\n      date, ticker, open, high, low, close, adj_close, volume\n    \"\"\"\n    # yfinance returns MultiIndex columns when multiple tickers are requested\n    if isinstance(data.columns, pd.MultiIndex):\n        try:\n            stacked = data.stack(level=0, future_stack=True)",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def build_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        description=\"Download B3 data from yfinance and save to Parquet (local) or S3 (partitioned).\"\n    )\n    parser.add_argument(\n        \"--tickers\",\n        required=True,\n        help=\"Comma-separated tickers (e.g., GOLL4,AZUL4,EMBR3 or GOLL4.SA,AZUL4.SA)\",\n    )\n    parser.add_argument(\"--start\", help=\"Start date YYYY-MM-DD\")",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.ingestion.WebScrapping",
        "description": "src.ingestion.WebScrapping",
        "peekOfCode": "def main() -> None:\n    args = build_parser().parse_args()\n    scraper = B3Scraper(\n        tickers=args.tickers,\n        start=args.start,\n        end=args.end,\n        period=args.period,\n        interval=args.interval,\n        output=args.output,\n    )",
        "detail": "src.ingestion.WebScrapping",
        "documentation": {}
    },
    {
        "label": "lambda_handler",
        "kind": 2,
        "importPath": "src.lambda.start_glue_job",
        "description": "src.lambda.start_glue_job",
        "peekOfCode": "def lambda_handler(event, context):\n    record = event[\"Records\"][0]\n    key = record[\"s3\"][\"object\"][\"key\"]\n    dt = DT_RE.search(key).group(1)\n    glue.start_job_run(\n        JobName=JOB_NAME,\n        Arguments={\"--dt\": dt}\n    )",
        "detail": "src.lambda.start_glue_job",
        "documentation": {}
    },
    {
        "label": "glue",
        "kind": 5,
        "importPath": "src.lambda.start_glue_job",
        "description": "src.lambda.start_glue_job",
        "peekOfCode": "glue = boto3.client(\"glue\")\nJOB_NAME = os.environ[\"GLUE_JOB_NAME\"]\nDT_RE = re.compile(r\"raw/dt=(\\d{4}-\\d{2}-\\d{2})/\")\ndef lambda_handler(event, context):\n    record = event[\"Records\"][0]\n    key = record[\"s3\"][\"object\"][\"key\"]\n    dt = DT_RE.search(key).group(1)\n    glue.start_job_run(\n        JobName=JOB_NAME,\n        Arguments={\"--dt\": dt}",
        "detail": "src.lambda.start_glue_job",
        "documentation": {}
    },
    {
        "label": "JOB_NAME",
        "kind": 5,
        "importPath": "src.lambda.start_glue_job",
        "description": "src.lambda.start_glue_job",
        "peekOfCode": "JOB_NAME = os.environ[\"GLUE_JOB_NAME\"]\nDT_RE = re.compile(r\"raw/dt=(\\d{4}-\\d{2}-\\d{2})/\")\ndef lambda_handler(event, context):\n    record = event[\"Records\"][0]\n    key = record[\"s3\"][\"object\"][\"key\"]\n    dt = DT_RE.search(key).group(1)\n    glue.start_job_run(\n        JobName=JOB_NAME,\n        Arguments={\"--dt\": dt}\n    )",
        "detail": "src.lambda.start_glue_job",
        "documentation": {}
    },
    {
        "label": "DT_RE",
        "kind": 5,
        "importPath": "src.lambda.start_glue_job",
        "description": "src.lambda.start_glue_job",
        "peekOfCode": "DT_RE = re.compile(r\"raw/dt=(\\d{4}-\\d{2}-\\d{2})/\")\ndef lambda_handler(event, context):\n    record = event[\"Records\"][0]\n    key = record[\"s3\"][\"object\"][\"key\"]\n    dt = DT_RE.search(key).group(1)\n    glue.start_job_run(\n        JobName=JOB_NAME,\n        Arguments={\"--dt\": dt}\n    )",
        "detail": "src.lambda.start_glue_job",
        "documentation": {}
    },
    {
        "label": "build_parser",
        "kind": 2,
        "importPath": "src.main",
        "description": "src.main",
        "peekOfCode": "def build_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        description=\"Download B3 data with default airline sector tickers and save to Parquet.\"\n    )\n    parser.add_argument(\n        \"--tickers\",\n        default=DEFAULT_TICKERS,\n        help=(\n            \"Comma-separated tickers \"\n            f\"(default: {DEFAULT_TICKERS}; accepts PETR4,VALE3 or PETR4.SA,VALE3.SA)\"",
        "detail": "src.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.main",
        "description": "src.main",
        "peekOfCode": "def main() -> None:\n    args = build_parser().parse_args()\n    scraper = B3Scraper(\n        tickers=args.tickers,\n        start=args.start,\n        end=args.end,\n        period=args.period,\n        interval=args.interval,\n        output=args.output,\n    )",
        "detail": "src.main",
        "documentation": {}
    },
    {
        "label": "DEFAULT_TICKERS",
        "kind": 5,
        "importPath": "src.main",
        "description": "src.main",
        "peekOfCode": "DEFAULT_TICKERS = \"GOLL4,AZUL4,EMBR3,EVEB31\"\ndef build_parser() -> argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        description=\"Download B3 data with default airline sector tickers and save to Parquet.\"\n    )\n    parser.add_argument(\n        \"--tickers\",\n        default=DEFAULT_TICKERS,\n        help=(\n            \"Comma-separated tickers \"",
        "detail": "src.main",
        "documentation": {}
    }
]